{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import statements"
      ],
      "metadata": {
        "id": "fpwtbn4j61Ig"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pip installations"
      ],
      "metadata": {
        "id": "IIzWDPNo3CId"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics"
      ],
      "metadata": {
        "id": "zx3Z5xJH3BMt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import statements"
      ],
      "metadata": {
        "id": "MuBWc8jL2AMp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from ultralytics import YOLO"
      ],
      "metadata": {
        "id": "7FTzSzuxy8eU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Directory paths"
      ],
      "metadata": {
        "id": "NRGJDXRk2Za4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "HIbZPgCt19Ok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_dir = '/content/drive/MyDrive/Research Files/Other files/Development/Dataset'\n",
        "segmentation_model = YOLO('/content/drive/MyDrive/Research Files/Other files/Development/YOLOv8 Trained Model/best.pt')"
      ],
      "metadata": {
        "id": "Kjyx7EYG2ZPO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Global variables"
      ],
      "metadata": {
        "id": "tm-ca5uSxd3p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tf.data.Dataset\n",
        "MAX_SEQUENCE_LENGTH = 45\n",
        "BATCH_SIZE = 4\n",
        "SHUFFLE_BUFFER_SIZE = 100\n",
        "PREFETCH_BUFFER_SIZE = tf.data.AUTOTUNE\n",
        "\n",
        "NEW_LENGTH = 291\n",
        "NEW_WIDTH = 218\n",
        "IMAGE_CHANNELS = 3\n",
        "\n",
        "LOSS_FUNCTION = \"mean_squared_error\"\n",
        "\n",
        "OPTIMIZER = Adadelta(learning_rate=LEARNING_RATE)\n",
        "LEARNING_RATE = 1.0\n",
        "\n",
        "EPOCHS = 50\n",
        "\n",
        "AUGMENT_PROBABILITY = 0.5"
      ],
      "metadata": {
        "id": "Y5aMyydZNdAV"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functions"
      ],
      "metadata": {
        "id": "nLuvbBgf2yDt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sequences(sequence_dir):\n",
        "    sequence_paths = sorted(\n",
        "        [os.path.join(sequence_dir, d) for d in os.listdir(sequence_dir) if os.path.isdir(os.path.join(sequence_dir, d))]\n",
        "    )\n",
        "    sequences = []\n",
        "    for seq_path in sequence_paths:\n",
        "        frame_paths = sorted(glob.glob(os.path.join(seq_path, '*.*')))  # Adjust the pattern if needed\n",
        "        sequences.append(frame_paths)\n",
        "    return sequences"
      ],
      "metadata": {
        "id": "tRCOB-cO2xdx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_tf_dataset(sequences):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(sequences)\n",
        "    return dataset"
      ],
      "metadata": {
        "id": "oYCZ9cpua2Vi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_image(image_path):\n",
        "    # Load image\n",
        "    img = cv2.imread(image_path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # ------------------------------\n",
        "\n",
        "    # Apply segmentation model\n",
        "    results = segmentation_model.predict(source=img, save=False, verbose=False)\n",
        "\n",
        "    # Get the segmentation mask\n",
        "    masks = results[0].masks\n",
        "    if masks is not None and len(masks.data) > 0:\n",
        "        # Assuming the first mask is the plant\n",
        "        mask = masks.data[0].cpu().numpy()  # Shape: (H, W)\n",
        "        mask = (mask * 255).astype(np.uint8)\n",
        "    else:\n",
        "        # If no mask is found, use an empty mask\n",
        "        mask = np.zeros((img.shape[0], img.shape[1]), dtype=np.uint8)\n",
        "\n",
        "    # Apply the mask to the image\n",
        "    segmented_img = cv2.bitwise_and(img, img, mask=mask)\n",
        "\n",
        "    # ------------------------------\n",
        "\n",
        "    # Resize the image\n",
        "    img_resized = cv2.resize(segmented_img, (NEW_LENGTH, NEW_WIDTH))\n",
        "\n",
        "    # ------------------------------\n",
        "\n",
        "    # Normalize the image to [0,1]\n",
        "    img_normalized = img_resized / 255.0\n",
        "\n",
        "    # ------------------------------\n",
        "\n",
        "    # Expand dimensions to add the channel dimension\n",
        "    img_normalized = np.expand_dims(img_normalized, axis=-1)\n",
        "\n",
        "    return img_normalized.astype(np.float32)"
      ],
      "metadata": {
        "id": "7_LZiaTsabgi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_sequence(frame_paths, max_length):\n",
        "    frames = []\n",
        "    for frame_path in frame_paths:\n",
        "        img = preprocess_image(frame_path)\n",
        "        frames.append(img)\n",
        "    frames = np.array(frames)\n",
        "\n",
        "    # Pad or truncate the sequence to 'max_length'\n",
        "    sequence_length = frames.shape[0]\n",
        "    if sequence_length < max_length:\n",
        "        # Pad with zeros at the beginning\n",
        "        pad_length = max_length - sequence_length\n",
        "        padding = np.zeros((pad_length, NEW_WIDTH, NEW_LENGTH, IMAGE_CHANNELS), dtype=np.float32)\n",
        "        frames = np.concatenate([padding, frames], axis=0)\n",
        "    else:\n",
        "        # Truncate the sequence\n",
        "        frames = frames[-max_length:]\n",
        "    return frames"
      ],
      "metadata": {
        "id": "5PN_XWKsadRH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_sequence_tf(frame_paths):\n",
        "    frames = tf.py_function(\n",
        "        func=preprocess_sequence,\n",
        "        inp=[frame_paths, MAX_SEQUENCE_LENGTH],\n",
        "        Tout=tf.float32\n",
        "    )\n",
        "    frames.set_shape([MAX_SEQUENCE_LENGTH, NEW_WIDTH, NEW_LENGTH, IMAGE_CHANNELS])\n",
        "    return frames"
      ],
      "metadata": {
        "id": "hYD5ILM_a9VO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_input_target(frames):\n",
        "    inputs = frames[:-1]   # Exclude the last frame\n",
        "    targets = frames[1:]   # Exclude the first frame\n",
        "    return inputs, targets"
      ],
      "metadata": {
        "id": "Kgp1BRSpbEmj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def augment_sequence(frames):\n",
        "    \"\"\"\n",
        "    Applies random augmentations to a sequence of frames.\n",
        "\n",
        "    Args:\n",
        "        frames: Tensor of shape (sequence_length, height, width, channels)\n",
        "\n",
        "    Returns:\n",
        "        Augmented frames of the same shape.\n",
        "    \"\"\"\n",
        "    def _augment(frames_np):\n",
        "        import numpy as np\n",
        "        import cv2\n",
        "\n",
        "        # Decide whether to apply augmentation\n",
        "        if np.random.rand() < AUGMENT_PROBABILITY:\n",
        "            # Define augmentation parameters\n",
        "            # Example: Random flip and rotation\n",
        "            flip_code = np.random.choice([None, 0, 1, -1])  # None: no flip, 0: vertical, 1: horizontal, -1: both\n",
        "            angle = np.random.uniform(-15, 15)  # Rotate between -15 to 15 degrees\n",
        "\n",
        "            # Define the rotation matrix\n",
        "            if angle != 0:\n",
        "                center = (IMAGE_WIDTH / 2, IMAGE_HEIGHT / 2)\n",
        "                rotation_matrix = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
        "\n",
        "            augmented_frames = []\n",
        "            for frame in frames_np:\n",
        "                frame = frame.squeeze()  # Shape: (height, width)\n",
        "\n",
        "                # Apply flip if selected\n",
        "                if flip_code is not None:\n",
        "                    frame = cv2.flip(frame, flip_code)\n",
        "\n",
        "                # Apply rotation if angle is not zero\n",
        "                if angle != 0:\n",
        "                    frame = cv2.warpAffine(frame, rotation_matrix, (IMAGE_WIDTH, IMAGE_HEIGHT), borderMode=cv2.BORDER_REFLECT)\n",
        "\n",
        "                # Expand dims to add channel back\n",
        "                frame = np.expand_dims(frame, axis=-1)\n",
        "                augmented_frames.append(frame)\n",
        "\n",
        "            augmented_frames = np.array(augmented_frames)\n",
        "            return augmented_frames.astype(np.float32)\n",
        "        else:\n",
        "            # No augmentation applied\n",
        "            return frames_np\n",
        "\n",
        "    # Use tf.py_function to apply the augmentation\n",
        "    augmented_frames = tf.py_function(func=_augment, inp=[frames], Tout=tf.float32)\n",
        "\n",
        "    # Set the shape\n",
        "    augmented_frames.set_shape([MAX_SEQUENCE_LENGTH, IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS])\n",
        "    return augmented_frames"
      ],
      "metadata": {
        "id": "_E0BDjD6aDHT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import dataset"
      ],
      "metadata": {
        "id": "p2UyJcU869UH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load dataset"
      ],
      "metadata": {
        "id": "Uh-xgyq670ow"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verify if dataset has been loaded"
      ],
      "metadata": {
        "id": "h_3cBH9772-C"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_6rtrvxYNefE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split training and validation sets"
      ],
      "metadata": {
        "id": "3ua6Vvtp8P7F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_sequences_dir = os.path.join(dataset_dir, 'train_set')\n",
        "val_sequences_dir = os.path.join(dataset_dir, 'val_set')\n",
        "test_sequences_dir = os.path.join(dataset_dir, 'test_set')"
      ],
      "metadata": {
        "id": "TNHv8SrkNdtD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_sequences = get_sequences(train_sequences_dir)\n",
        "val_sequences = get_sequences(val_sequences_dir)\n",
        "test_sequences = get_sequences(test_sequences_dir)"
      ],
      "metadata": {
        "id": "0XxLhTnv29Ei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = create_tf_dataset(train_sequences)\n",
        "val_dataset = create_tf_dataset(val_sequences)\n",
        "test_dataset = create_tf_dataset(test_sequences)"
      ],
      "metadata": {
        "id": "Uu-BNDEPa5UG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = train_dataset.map(process_sequence_tf, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "val_dataset = val_dataset.map(process_sequence_tf, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "test_dataset = test_dataset.map(process_sequence_tf, num_parallel_calls=tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "-HkYYmiia_4-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply data augmentation only to the training set\n",
        "train_dataset = train_dataset.map(lambda x: augment_sequence(x), num_parallel_calls=tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "395RIMQpaqjK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = train_dataset.map(create_input_target, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "val_dataset = val_dataset.map(create_input_target, num_parallel_calls=tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "79r8RoDrbIbx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verify if training and validation sets are splitted"
      ],
      "metadata": {
        "id": "2U5NcTT09A72"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZRSGGuACNfnu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Segment plant object"
      ],
      "metadata": {
        "id": "nE319qLM3kU1"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HQSf15XG3k_I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocess dataset"
      ],
      "metadata": {
        "id": "j12L1ioT8dEn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For the training dataset\n",
        "train_dataset = (\n",
        "    train_dataset\n",
        "    .cache()\n",
        "    .shuffle(SHUFFLE_BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE)\n",
        "    .prefetch(PREFETCH_BUFFER_SIZE)\n",
        ")\n",
        "\n",
        "val_dataset = (\n",
        "    val_dataset\n",
        "    .cache()\n",
        "    .batch(BATCH_SIZE)\n",
        "    .prefetch(PREFETCH_BUFFER_SIZE)\n",
        ")\n",
        "\n",
        "test_dataset = (\n",
        "    test_dataset\n",
        "    .cache()\n",
        "    .batch(BATCH_SIZE)\n",
        "    .prefetch(PREFETCH_BUFFER_SIZE)\n",
        ")"
      ],
      "metadata": {
        "id": "9CZCy_b_eiPM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verify shapes"
      ],
      "metadata": {
        "id": "4VjHCYhv399b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example of verifying shapes\n",
        "for inputs, targets in train_dataset.take(1):\n",
        "    print('Inputs shape:', inputs.shape)   # Expected: (BATCH_SIZE, sequence_length, 218, 291, 1)\n",
        "    print('Targets shape:', targets.shape) # Expected: (BATCH_SIZE, sequence_length, 218, 291, 1)"
      ],
      "metadata": {
        "id": "krGZGtbk3-gh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Develop model"
      ],
      "metadata": {
        "id": "cadQ_PfU7Ep9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *Iteration X*"
      ],
      "metadata": {
        "id": "GYE5r-eG7Eil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Build model"
      ],
      "metadata": {
        "id": "LtVw_hw_7Ef-"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_BKD_usObsC-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualize model"
      ],
      "metadata": {
        "id": "r9Wrnz_N8uwh"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LTg8T0mgveAM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compile model"
      ],
      "metadata": {
        "id": "Gl5yZ_Zn83Rz"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SXW1mwyXvcjx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train model"
      ],
      "metadata": {
        "id": "JsUBshFZ7Ed5"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WZlV7Zqrvlsv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot results"
      ],
      "metadata": {
        "id": "1LXJl_VV9J9v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *Iteration 1*"
      ],
      "metadata": {
        "id": "HyyOqWAHNwiS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Build model"
      ],
      "metadata": {
        "id": "8Nregge1NzM1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential([\n",
        "    layers.Input(shape=(None, NEW_WIDTH, NEW_LENGTH, IMAGE_CHANNELS)),\n",
        "    layers.ConvLSTM2D(\n",
        "        filters=40, kernel_size=(3, 3), padding=\"same\", return_sequences=True\n",
        "    ),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.ConvLSTM2D(\n",
        "        filters=40, kernel_size=(3, 3), padding=\"same\", return_sequences=True\n",
        "    ),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.ConvLSTM2D(\n",
        "        filters=40, kernel_size=(3, 3), padding=\"same\", return_sequences=True\n",
        "    ),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.ConvLSTM2D(\n",
        "        filters=40, kernel_size=(3, 3), padding=\"same\", return_sequences=True\n",
        "    ),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Conv3D(\n",
        "        filters=1, kernel_size=(3, 3, 3), activation=\"sigmoid\", padding=\"same\"\n",
        "    ),\n",
        "])"
      ],
      "metadata": {
        "id": "lIf6UzKHOBo1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualize model"
      ],
      "metadata": {
        "id": "FdpvMJVdN4I9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "IqBuTHQ7OCFO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compile model"
      ],
      "metadata": {
        "id": "yIlTq1HON6Fc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=LOSS_FUNCTION, optimizer=OPTIMIZER)"
      ],
      "metadata": {
        "id": "9HhpLlVaOC_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train model"
      ],
      "metadata": {
        "id": "5TlMBtOWN7Lh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    validation_data=val_dataset,\n",
        "    epochs=EPOCHS\n",
        ")"
      ],
      "metadata": {
        "id": "-xtJL_eaODeP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot results"
      ],
      "metadata": {
        "id": "vwUOoUblN845"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training & validation loss values\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "if 'val_loss' in history.history:\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DSc5G2a-OEGo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualize results"
      ],
      "metadata": {
        "id": "LKHUUzTgv5-S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select a sequence from the training set\n",
        "example_sequence_paths = train_sequences[0]  # Adjust index as needed\n",
        "example_sequence = preprocess_sequence(example_sequence_paths, MAX_SEQUENCE_LENGTH)\n",
        "\n",
        "# Prepare inputs\n",
        "example_input = example_sequence[:-1]  # Inputs\n",
        "example_target = example_sequence[1:]  # Ground truth\n",
        "\n",
        "# Expand dimensions to simulate batch size of 1\n",
        "example_input = np.expand_dims(example_input, axis=0)  # Shape: (1, sequence_length, 40, 40, 1)\n",
        "\n",
        "# Predict the sequence\n",
        "predicted_sequence = model.predict(example_input)\n",
        "predicted_sequence = predicted_sequence[0]  # Remove batch dimension\n",
        "\n",
        "# Visualize the results\n",
        "num_frames = 5  # Number of frames to display\n",
        "\n",
        "plt.figure(figsize=(15, 6))\n",
        "\n",
        "# Original frames\n",
        "for i in range(num_frames):\n",
        "    plt.subplot(2, num_frames, i + 1)\n",
        "    plt.imshow(example_sequence[i])\n",
        "    plt.title(f'Frame {i + 1} (Original)')\n",
        "    plt.axis('off')\n",
        "\n",
        "# Predicted frames\n",
        "for i in range(num_frames):\n",
        "    plt.subplot(2, num_frames, num_frames + i + 1)\n",
        "    if i < 3:\n",
        "        # Show original frames for the first 3 frames\n",
        "        plt.imshow(example_sequence[i])\n",
        "        plt.title(f'Frame {i + 1} (Original)')\n",
        "    else:\n",
        "        # Show predicted frames for subsequent frames\n",
        "        plt.imshow(example_sequence[i])\n",
        "        plt.title(f'Frame {i + 1} (Predicted)')\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VrezEgcfv7YU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test model"
      ],
      "metadata": {
        "id": "mReqKY8O7EcE"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gU7NYGz-N0iH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}